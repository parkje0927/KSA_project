### 1. 자연어처리 소개
#### 1.4 자연어처리 연구의 패러다임
- 규칙 기반, 통계 기반, 딥러닝 기반 

#### 1.5 딥러닝을 사용하는 자연어처리 연구
- 딥러닝을 사용하는 자연어처리의 연구 순서
- 단어 임베딩(word embedding)
	+ 자연어로 이루어진 문장을 컴퓨터가 입력 받을 수 있도록 하는 문장의 전처리 과정(모델의 일부)
	+ 다양한 방법이 존재하나, 단어간 연관성 등을 유지하는 벡터화 방법이 많이 쓰임
	+ 문법적으로만 사용되는 단어는 일반적으로 삭제
	+ 사전에 임베딩된 단어 사전을 사용하여 연구를 진행하는 경우 많음

- 코퍼스(Corpus), 모델
	+ 매우 많은 문장을 정제하여 모은 것
	+ Corpora(복수형)
	+ 통계 기반 & 딥러닝 기반 자연어처리에 가장 핵심인 자료
	+ 연구 필요성에 따라 문장 성분을 문장에 기입하거나 대응되는 번역문과 쌍을 구성하는 등, 연구에 사용할(모델이 학습해야 할) 정보를 함께 기입
	+ 예시) 형태소 분석 : I am a boy => <주어> <동사> <관사> <보어>

#### 1.6 딥러닝을 사용하는 다른 연구 분야와 자연어처리 비교
- AI를 활용한 주요 분야
	+ computer vision
	+ NLP
	+ speech processing

- 자연어처리
	+ 이산적인 값을 다룸(단어나 문장 단위)
	+ 분류 문제로 접근 가능
	+ 샘플의 확률 값을 구할 수 있음
	+ 문장 생성(자연어 생성) => auto-regressive 속성 지님(앞에 단어를 보고 뒤에 단어를 유추할 수 있음) / GAN 적용 불가

- 자연어처리의 필수 요건
	+ 언어적 지식 필요(예시-한국어의 언어적 특성은 무엇인가?)
	+ 어려운 전처리 과정(문제에 따른 정제 과정 필요)

---

### 2. 자연어처리를 위한 수학
#### 2.1 확률의 기초


---

### 4. 텍스트의 처리
#### 4.0 NLP 프로젝트 워크플로우
- 문제 정의(x, y정의) 
- -> 데이터 수집(문제 정의 고려한 수집, 레이블링) 
- -> 데이터 전처리 및 분석(형태 가공, 특수문자 및 의미 없는 문자 삭제) 
- -> 알고리즘 적용(가설 수립, 구현 및 적용) 
- -> 평가(실험 설계/수행, 테스트셋 구성) 
- -> 서비스 릴리즈(API 통합 배포, 필요시 유지 보수)
- 예시) 메일 -> 햄 or 스팸 / 채팅 -> 악성 or 악성이 아닌지 / sns 글 -> 긍정 or 부정

#### 4.0 NLP 전처리 워크플로우
- 코퍼스 수집(데이터)
	+ 구입 또는 외주 : 편하지만 품질이 보장되지 않는다.
	+ 직접 수집(크롤링) : 시간이 걸리지만 막상 하면 괜찮다.
- -> 다듬기(정제)
	+ 문제에 따른 노이즈 제거
	+ 인코딩 변환 : UTF-8 / UTF-16
- -> 라벨링
	+  문장 또는 단어 단위로
- -> 분절
	+ 형태소 분석기 활용
- -> 하위 단어 분할
	+ 단어보다 더 작은 의미 단위로 분할
- -> 배치화
	+ 사전 생성
	+ word2index 매핑
	+ 효율화를 위한 처리(성능에 영향을 주지 않는다면 길이가 비슷한 문장끼리 정렬된 상태로 학습시키는 것을 선호) 

#### 4.1 비정형 데이터 내의 오류
- 비정형 데이터
	+ 일정한 규격이나 형태를 지닌 숫자 데이터와 달리 그림이나 영상, 문서처럼 형태와 구조가 다른 구조화되지 않는 데이터
	+ 정의될 수 있는 확실한 기준이 없어 정의 내리고 이해하기 어려움
- 분석을 위해서는 비정형 데이터의 정형화가 요구됨. 

#### 4.2 텍스트 문서의 변환
- 목적으로 하는 파일로부터 텍스트를 추출하는 것이 전처리의 첫 번째 단계
	+ 일반적을 문서들은 사람이 읽기 간편한 형식으로 저장되어 있지만 파일 형식에 따라 저장 방법이 달라 시스템에게는 읽기 곤란
- '문서 파일'을 '문서'로 바꾸는 작업 수행 -> 목표 어휘언어의 문자만 남아있어야 함
- 코딩 관련 커맨드 제거, 필요하지 않은 특수문자 제거 -> 순수하게 문장 단위로 남은 텍스트
- 단어를 구분 짓는 잣대를 통일, 차후 텍스트 처리 시 일관성 부족으로 생길 오류나 불상사를 방지
- train, test, val 데이터에 대해 동일한 전처리를 해야 함
- 인터렉티브한 노이즈 제거 과정
	+ 규칙에 의해 노이즈를 제거하기 때문에 노이즈 전부를 제거하는 것은 어려움
	+ 따라서 반복적인 규칙생성 및 적용 과정이 필요
	+ 끝이 없는 과정 => 노력과 품질 사이의 trade-off

#### 4.3 띄어쓰기 교정 방법
- 띄어쓰기 : 한국어는 크게 의미분절, 가독성, 의미혼용 방지의 용도
- 형태소 분석기를 사용하는 규칙기반의 분석적인 방법 : koNLPy
- 어절 블록 양방향 알고리즘
- 통계, 확률 기반 : 수정방향이 옳을 확률이 높은 후보들을 차례로 나열
	
#### 4.4 철자 및 맞춤법 교정방법
##### 규칙기반
- 형태소 분석기로 하나의 어절이 입력된 어절을 형태소로 분절
- 분절 결과가 적합한지 접속 정보표를 이용하여 확인

##### 통계, 확률 기반
- Bayesian inference model
	+ 올바른 교정결과를 도출하기 위해 주어진 단어로부터 오타가 일어날 확률을 확률적으로 계산하는 방법
	+ 이미, p(a), p(b) 의 확률을 알고 있다. 
	+ 우리의 믿음을 첨가해주면, 데이터에 100% 의존하지 않아도 된다.
	+ 책 => 세상에서 가장 쉬운 베이즈통계학 입문

---

### 5. 어휘 분석(Lexial analysis)
#### 5.1 형태소 분석
##### 형태소 분석 절차
- 어휘 분석 : 단어의 구조를 식별하고 분석을 통한 어휘의 의미와 품사에 관한 단어 수준의 연구
- 형태소 분석 : 더 이상 분해될 수 없는 최소한의 의미 단위인 형태소를 자연어의 제약 조건과 문법 규칙에 맞춰 분석하는 것 
- 1) 단어에서 최소 의미를 포함하는 형태소로 분리한다.
	+ 형태소 분석의 처리 대상인 어절은 하나 이상의 형태소가 연결된 것
	+ 한국어에서 형태소가 연결될 때, 형태소의 변형이 일어나기 때문에 형태소 원형의 복원이 필요함
- 2) 형태론적 변형이 일어난 형태소의 원형을 찾는다.
	+ 형태소와 그 형태소의 품사를 쌍으로 나타낸 것을 형태소품사쌍이라고 함
- 3) 단어와 사전들 사이의 결합 조건에 따라 옳은 분석 후보를 선택한다. 
	+ 예시) "나_대명사" + "는_조사"

##### 영어 형태소 분석
- 영어에서 최소 단위의 의미를 갖는 기본 단위는 단어
	+ word : am / stemming : am / lemmatization(원형) : be
	+ word : has / stemming : ha / lemmatization(원형) : hava
- 일반적으로 영어의 형태소는 접사
- 접사를 제거했을 때 의미가 바뀌는 단어들이 존재하며, 최소한의 의미를 가진 형태소를 찾아 원형 분석 필요함

##### 한국어 형태소 분석 라이브러리
- 한국어 형태소 분석기의 오픈 라이브러리
	+ koNLPy : 한나눔, 코모란, 미캡, 꼬꼬마, 트위터
	+ Khiii : 딥러닝(CNN)을 이용한 형태소 분석기 

#### 5.2 품사 태깅
##### 품사 태깅이란?
- 품사 : 단어의 기능, 형태, 의미에 따라 나눈 것을 말함
- 태깅 : 같은 단어에 대해 의미가 다를 경우(중의성)를 해결하기 위해 부가적인 언어의 정보를 부착

##### 형태론적 중의성 해결 방법
- 자동 품사 태깅 방법
	+ 문맥틀 형식으로 규칙을 기술하는 방법
- 통계적 품사 태깅 방법
	+ 변형 마르코프 모형에 기반한 방법

##### 품사 태깅 접근법
- 규칙 기반의 접근법
	+ 언어 정보에서 생성되는 규칙 형태로 표현, 이를 적용하여 태깅을 수행함
	+ 긍정 정보, 부정 정보, 수정 정보를 이용하여 중의성을 해결하고 태깅을 부착하는 방법
	+ 뒤에 오는 단어를 바탕으로 추정한다.
	+ "나_동사" or "나_대명사" + "새" => 뒤에 "새"라는 단어를 통해 "나_동사" 라고 추정

- 통계 기반의 접근법(Hidden Markov Model)
	+ 태그가 부착된 대량의 코퍼스가 주어지면 태깅에 적합한 모델을 선정하고 코퍼스에서 추출된 통계정보를 이용
	+ 대표적으로 어휘 확률만을 이용하는 방법 : Hidden Markov Model(HMM) => 가장 성능이 좋은 접근 방법
	+ 태깅되지 않은 코퍼스로부터 unsupervised learning 을 통해 어휘 확률만을 획득
	+ 주어진 문장에서 형태소의 품사 태그 정보를 숨긴채로 확률 정보를 이용하여 가장 가능성이 높은 경로를 찾음
	
- 딥러닝 기반의 접근법
	+ 언어 처이에 있어서 딥러닝의 효과
	+ (1) 데이터로부터 특징을 자동으로 학습
	+ (2) 폭넓은 문제 정보를 다룰 수 있음
	+ (3) 모델에 적합한 출력을 다루기가 간단함
	+ (4) 언어가 아닌 이미지나 음성과 같은 모델들 간의 상호작용 가능, 멀티 모달 모델 구축 용이












	
	